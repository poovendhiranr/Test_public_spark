{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrrYoWytGqfSRbWHt38jt1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poovendhiranr/Test_public_spark/blob/main/Analysis_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrUxQIgdoIKT",
        "outputId": "0f263f63-16fe-428f-aa4c-fbabf88a312f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.8/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, LongType,ArrayType\n",
        "import math \n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql import types \n",
        "from pyspark.sql import Window\n",
        "spark = SparkSession.builder.master(\"local[*]\") \\\n",
        "                    .appName('Analysis') \\\n",
        "                    .getOrCreate()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary Report (All Time)"
      ],
      "metadata": {
        "id": "lWv2mmScQKqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.csv(\"/content/datafiles\",header=True)\n",
        "meta=spark.read.csv(\"/content/meta/symbol_metadata.csv\",header=True)\n",
        "df1=df.withColumn(\"filename\",f.input_file_name())\n",
        "df2=df1.withColumn(\"filename\",f.regexp_replace(f.split(df1['filename'], '/').getItem(5),'.csv',''))\n",
        "df3=df2.join(meta,f.trim(df2.filename)==f.trim(meta.Symbol),\"inner\")\n",
        "df3.orderBy('timestamp') \\\n",
        "    .groupBy(\"Sector\") \\\n",
        "    .agg(f.round(f.avg('open'),2).alias('Avg_OpenPrice'), \\\n",
        "         f.round(f.avg('close'),2).alias('Avg_ClosePrice'), \\\n",
        "         f.round(f.max('high'),2).alias('Max_high'), \\\n",
        "         f.round(f.min('low'),2).alias('Min_low'), \\\n",
        "         f.round(f.avg('volume'),2).alias('Avg_volume')).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a22FA7L6r_Ws",
        "outputId": "9b7354bc-6655-487c-af13-3bc022403d6c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------+--------------+--------+-------+-------------+\n",
            "|              Sector|Avg_OpenPrice|Avg_ClosePrice|Max_high|Min_low|   Avg_volume|\n",
            "+--------------------+-------------+--------------+--------+-------+-------------+\n",
            "|ENERGY & TRANSPOR...|        17.56|         17.56|   99.99|    0.2|   4669611.43|\n",
            "|             FINANCE|         19.6|         19.61|    9.99|   10.0|     10065.09|\n",
            "|       LIFE SCIENCES|         45.3|         45.31|   99.93|  10.29|    1772380.1|\n",
            "|       MANUFACTURING|        32.83|         32.84|   92.32|  10.09|   5396276.95|\n",
            "|REAL ESTATE & CON...|        10.18|         10.17|    9.99|   10.0|    212976.18|\n",
            "|          TECHNOLOGY|        72.61|         72.61|   99.99|   0.09|1.149873898E7|\n",
            "|    TRADE & SERVICES|        58.67|         58.69|    99.9|  100.0|    2475920.9|\n",
            "+--------------------+-------------+--------------+--------+-------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QRj1_xZdjstl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggregation summary details for a given sector(s) over the time period."
      ],
      "metadata": {
        "id": "b7oaJPYPhYsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------input---------------------------------\n",
        "dt=[('2021-01-01','2022-05-26',['TECHNOLOGY','FINANCE'])]\n",
        "#----------------------------------------------------------\n",
        "deptSchema = StructType([       \n",
        "    StructField('dept_name', StringType(), True),\n",
        "    StructField('dept_id', StringType(), True),\n",
        "    StructField('array_valuer',ArrayType(StringType(),False)  ,True)\n",
        "])\n",
        "unioned_df = None\n",
        "df_filter  =spark.createDataFrame(data=dt,schema=deptSchema)\n",
        "df1_filter =df_filter.withColumn(\"sector_value\",f.explode(f.col('array_valuer'))).drop('array_valuer')\n",
        "dd_c={x[2]:[x[0],x[1]] for x in df1_filter.rdd.collect()}  \n",
        "for i,k in dd_c.items():\n",
        "  sector_value= i\n",
        "  start_date=k[0]\n",
        "  end_date  =k[1]\n",
        "  df_temp   =df3.filter((f.col(\"timestamp\")>=start_date) & (f.col(\"timestamp\")<=end_date)&(f.col(\"Sector\")==sector_value))  \n",
        "  \n",
        "  if not unioned_df:\n",
        "        unioned_df = df_temp\n",
        "  else:\n",
        "        unioned_df = unioned_df.union(df_temp)\n",
        "agg_df=unioned_df.orderBy('timestamp') \\\n",
        "          .groupBy(\"Sector\") \\\n",
        "          .agg(f.round(f.avg('open'),2).alias('Avg_OpenPrice'), \\\n",
        "           f.round(f.avg('close'),2).alias('Avg_ClosePrice'), \\\n",
        "           f.round(f.max('high'),2).alias('Max_high'), \\\n",
        "           f.round(f.min('low'),2).alias('Min_low'), \\\n",
        "           f.round(f.avg('volume'),2).alias('Avg_volume'))\n",
        "\n",
        "agg_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDCib7lBMhhz",
        "outputId": "de85d361-13f4-47d9-e9ed-6584ba0d99fd"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+--------------+--------+-------+-------------+\n",
            "|    Sector|Avg_OpenPrice|Avg_ClosePrice|Max_high|Min_low|   Avg_volume|\n",
            "+----------+-------------+--------------+--------+-------+-------------+\n",
            "|   FINANCE|        24.83|         24.87|    35.0|  14.38|     25198.98|\n",
            "|TECHNOLOGY|        78.96|         78.99|    99.9| 100.11|2.413942584E7|\n",
            "+----------+-------------+--------------+--------+-------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggregation summary details for all the symbol(s) in a given sector over\n",
        "the time period."
      ],
      "metadata": {
        "id": "Z4C1dRh-jazZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------input---------------------------------\n",
        "dt=[('2021-01-01','2022-05-26',['TECHNOLOGY','FINANCE'])]\n",
        "#----------------------------------------------------------\n",
        "deptSchema = StructType([       \n",
        "    StructField('dept_name', StringType(), True),\n",
        "    StructField('dept_id', StringType(), True),\n",
        "    StructField('array_valuer',ArrayType(StringType(),False)  ,True)\n",
        "])\n",
        "unioned_df1 = None\n",
        "df_filter1  =spark.createDataFrame(data=dt,schema=deptSchema)\n",
        "df1_filter1 =df_filter.withColumn(\"sector_value\",f.explode(f.col('array_valuer'))).drop('array_valuer')\n",
        "dd_c1={x[2]:[x[0],x[1]] for x in df1_filter.rdd.collect()}  \n",
        "for i,k in dd_c1.items():\n",
        "  sector_value= i\n",
        "  start_date=k[0]\n",
        "  end_date  =k[1]\n",
        "  df_temp   =df3.filter((f.col(\"timestamp\")>=start_date) & (f.col(\"timestamp\")<=end_date)&(f.col(\"Sector\")==sector_value))  \n",
        "  if not unioned_df:\n",
        "        unioned_df = df_temp\n",
        "  else:\n",
        "        unioned_df = unioned_df.union(df_temp)\n",
        "agg_df1=unioned_df.orderBy('timestamp') \\\n",
        "          .groupBy(\"Symbol\",\"Name\") \\\n",
        "          .agg(f.round(f.avg('open'),2).alias('Avg_OpenPrice'), \\\n",
        "           f.round(f.avg('close'),2).alias('Avg_ClosePrice'), \\\n",
        "           f.round(f.max('high'),2).alias('Max_high'), \\\n",
        "           f.round(f.min('low'),2).alias('Min_low'), \\\n",
        "           f.round(f.avg('volume'),2).alias('Avg_volume'))\n",
        "agg_df1.show()          \n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huIJ3bPbfHzU",
        "outputId": "3840aff5-1544-4c86-edbb-985b9fed96cf"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+-------------+--------------+--------+-------+-------------+\n",
            "|Symbol|                Name|Avg_OpenPrice|Avg_ClosePrice|Max_high|Min_low|   Avg_volume|\n",
            "+------+--------------------+-------------+--------------+--------+-------+-------------+\n",
            "|  AAPL|           Apple Inc|       145.34|         145.4|  182.94| 116.21|9.132503343E7|\n",
            "|  ACNB|    ACNB Corporation|        29.02|         29.04|    35.0|  24.06|     21827.67|\n",
            "|  BCML|         BayCom Corp|        18.36|         18.37|   22.73|  14.38|     34451.94|\n",
            "|  DELL|Dell Technologies...|        82.81|         82.87|    99.9| 100.11|   3121529.36|\n",
            "|  MYFW|First Western Fin...|         27.1|         27.21|    34.2|   17.3|     19317.34|\n",
            "|  NTAP|          NetApp Inc|        81.26|         81.28|   96.82|  58.83|   1708967.17|\n",
            "|  QMCO| Quantum Corporation|         6.42|          6.41|    9.47|   2.36|    402173.39|\n",
            "+------+--------------------+-------------+--------------+--------+-------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nWbpdgaU6mO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zNoeylfh6m_f"
      }
    }
  ]
}